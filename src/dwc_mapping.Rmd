---
title: "Darwin Core mapping"
subtitle: "For: Ad hoc checklist of alien species in Belgium"
author:
- Lien Reyserhove
- Peter Desmet
- Quentin Groom
- Tim Adriaens
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    number_sections: true
    toc: true
    toc_depth: 3
    toc_float: true
---

This document describes how we map the checklist data to Darwin Core. The source file for this document can be found [here](https://github.com/trias-project/ad-hoc-checklist/blob/master/src/dwc_mapping.Rmd).

# Setup

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Load libraries:

```{r}
library(tidyverse)      # To transform data
library(magrittr)       # To use %<>% pipes
library(here)           # To find files
library(janitor)        # To clean input data
library(googlesheets)   # To import and read Google spreadsheets 
library(stringr)        # To perform string operations
library(digest)         # To generate hashes
library(rgbif)          # To use GBIF services
```

# Read source data

The original spreadsheet can be found [here](https://docs.google.com/spreadsheets/d/1LeXXbry2ArK2rngsmFjz_xErwE1KwQ8ujtvHNmTVA6E/edit#gid=0). We need to retrieve this spreadsheet and select the specific worksheet first:

Retrieve the spreadsheet:

```{r connect_google_spreadsheets}
retrieve_spreadsheet <- gs_title("ad hoc checklist")
```

Select the data in the worksheet `checklist`:

```{r read_source_data}
input_data <- retrieve_spreadsheet %>% gs_read("checklist") # Also trims values
```

We want to add a copy of the source data to the repository:

```{r}
write.csv(input_data, file = here("data", "raw", "ad_hoc_checklist_dump.csv"), na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

Preview data: 

```{r}
input_data %>% head()
```

# Process source data

## Tidy data

Clean data somewhat:

```{r}
input_data %<>%
  remove_empty("rows") %>%    # Remove empty rows
  clean_names()               # Have sensible (lowercase) column names
```

Add prefix `input_` to all column names to avoid name clashes with Darwin Core terms:

```{r}
colnames(input_data) <- paste0("input_", colnames(input_data))
```

## Scientific names

No cleaning required.

## Taxon IDs

To link taxa with information in the extension(s), each taxon needs a unique and relatively stable `taxonID`. Here we create one in the form of `dataset_shortname:taxon:hash`, where `hash` is unique code based on scientific name and kingdom (that will remain the same as long as scientific name and kingdom remain the same):

```{r}
vdigest <- Vectorize(digest) # Vectorize digest function to work with vectors
input_data %<>% mutate(input_taxon_id = paste(
  "ad-hoc-checklist",
  "taxon",
  vdigest(paste(input_scientific_name, input_kingdom), algo = "md5"),
  sep = ":"
))
```

## Preview data

Show the number of taxa and distributions per kingdom and rank:

```{r}
input_data %>%
  group_by(input_kingdom, input_taxon_rank) %>%
  summarize(
    `# taxa` = n_distinct(input_taxon_id),
    `# distributions` = n()
  ) %>%
  adorn_totals("row")
```

Preview data:

```{r}
input_data %>% head()
```

# Taxon core

## Pre-processing

Create a dataframe with unique taxa only (ignoring multiple distribution rows):

```{r start_taxon}
taxon <- input_data %>% distinct(input_taxon_id, .keep_all = TRUE)
```

## Term mapping

Map the data to [Darwin Core Taxon](http://rs.gbif.org/core/dwc_taxon_2015-04-24.xml).
 
### language

```{r}
taxon %<>% mutate(language = "en")
```

### license

```{r}
taxon %<>% mutate(license = "http://creativecommons.org/publicdomain/zero/1.0/")
```

### rightsHolder

```{r}
taxon %<>% mutate(rightsHolder = "INBO") 
```

### accessRights

```{r}
taxon %<>% mutate(accessRights = "https://www.inbo.be/en/norms-data-use") 
```

### datasetID

```{r}
taxon %<>% mutate(datasetID = "") 
```

### institutionCode

```{r}
taxon %<>% mutate(institutionCode = "INBO") 
```

### datasetName

```{r}
taxon %<>% mutate(datasetName = "Ad hoc checklist of alien species in Belgium") 
```

### taxonID

```{r}
taxon %<>% mutate(taxonID = input_taxon_id)
```

### scientificName

```{r}
taxon %<>% mutate(scientificName = input_scientific_name) 
```

### kingdom

Inspect values:

```{r}
taxon %>%
  group_by(input_kingdom) %>%
  count()
```

Map values:

```{r}
taxon %<>% mutate(kingdom = input_kingdom)
```

### phylum

Inspect values:

```{r}
taxon %>%
  group_by(input_phylum) %>%
  count()
```

Map values:

```{r}
taxon %<>% mutate(phylum = input_phylum)
```

### order

Inspect values:

```{r}
taxon %>%
  group_by(input_order) %>%
  count()
```

Map values:

```{r}
taxon %<>% mutate(order = input_order)
```

### family

Inspect values:

```{r}
taxon %>%
  group_by(input_family) %>%
  count()
```

Map values:

```{r}
taxon %<>% mutate(family = input_family)
```

### genus

Inspect values:

```{r}
taxon %>%
  group_by(input_genus) %>%
  count()
```

Map values:

```{r}
taxon %<>% mutate(genus = input_genus)
```

### taxonRank

Inspect values:

```{r}
taxon %>%
  group_by(input_taxon_rank) %>%
  count()
```

Map values:

```{r}
taxon %<>% mutate(taxonRank = input_taxon_rank)
```

### nomenclaturalCode

```{r}
taxon %<>% mutate(nomenclaturalCode = input_nomenclatural_code)
```

## Post-processing

Remove the original columns:

```{r}
taxon %<>% select(-starts_with("input_"))
```

Sort on `taxonID` (to maintain some consistency between updates of the dataset):

```{r}
taxon %<>% arrange(taxonID)
```

Preview data:

```{r}
taxon %>% head()
```

Save to CSV:

```{r}
write.csv(taxon, file = here("data", "processed", "taxon.csv"), na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

# Literature references extension

In this extension we will express references from `input_source`, separated and gathered.

## Pre-processing

Create a dataframe with all data (including multiple distributions), to capture potentially different `input_source` for different distributions of the same taxa:

```{r start_references}
literature_references <- input_data
```

Separate values on `|` in a maximum of 3 columns:

```{r}
literature_references %<>% separate(
  input_source,
  into = paste0("reference_", c(1:3)),
  sep = " \\| ",
  extra = "drop"
)
```

Gather and trim values:

```{r}
literature_references %<>% gather(key, value, starts_with("reference_"), na.rm = TRUE) %>%
  mutate(value = str_trim(value))
```

## Term mapping

Map the data to [Literature References](http://rs.gbif.org/extension/gbif/1.0/references.xml).

### taxonID

```{r}
literature_references %<>% mutate(taxonID = input_taxon_id)
```

### identifier

Extract the URL from reference using regex:

```{r}
literature_references %<>% mutate(identifier = str_extract(value, "http\\S+"))
```

### bibliographicCitation

```{r}
literature_references %<>% mutate(bibliographicCitation = value) 
```

## Post-processing

Remove the original columns:

```{r}
literature_references %<>% select(-starts_with("input_"), -key, -value)
```

Remove duplicates (same reference for same taxon):

```{r}
literature_references %<>% distinct()
```

Sort on `taxonID`:

```{r}
literature_references %<>% arrange(taxonID)
```

Preview data:

```{r}
literature_references %>% head()
```

Save to CSV:

```{r}
write.csv(literature_references, file = here("data", "processed", "references.csv"), na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

# Distribution extension

## Pre-processing

Create a dataframe with all data (including multiple distributions):

```{r}
distribution <- input_data
```

## Term mapping 

Map the data to [Species Distribution](http://rs.gbif.org/extension/gbif/1.0/distribution.xml).

### taxonID

```{r}
distribution %<>% mutate(taxonID = input_taxon_id) 
```

### locationID

Currently map for Belgian regions only:

```{r}
distribution %<>% mutate(locationID = case_when(
  is.na(input_location) & input_country_code == "BE" ~ "ISO_3166-2:BE",
  input_location == "Flanders" ~ "ISO_3166-2:BE-VLG",
  input_location == "Wallonia" ~ "ISO_3166-2:BE-WAL",
  input_location == "Brussels" ~ "ISO_3166-2:BE-BRU"
))
```

### locality

Currently map for Belgian regions only:

```{r}
distribution %<>% mutate(locality = case_when(
  is.na(input_location) & input_country_code == "BE" ~ "Belgium",
  input_location == "Flanders" ~ "Flemish Region",
  input_location == "Wallonia" ~ "Walloon Region",
  input_location == "Brussels" ~ "Brussels-Capital Region"
))
```

### countryCode

```{r}
distribution %<>% mutate(countryCode = input_country_code)
```

### occurrenceStatus

```{r}
distribution %<>% mutate(occurrenceStatus = input_occurrence_status)
```

### establishmentMeans

```{r}
distribution %<>% mutate(establishmentMeans = "introduced")
```

### eventDate

Information for `eventDate` is contained in `input_date_first_observation` and `input_date_last_observation`, which we will express here in an ISO 8601 date format `yyyy/yyyy` (`start_date/end_date`).

Inspect `input_data_first_observation`:

```{r}
distribution %>%
  group_by(input_date_first_observation) %>%
  count()
```

Clean `input_date_first_observation` (remove `>`):

```{r}
distribution %<>% mutate(input_date_first_observation = str_replace_all(input_date_first_observation, ">", "")) 
```

`start_date_first_observation` contains empty values. For those we'll consider the publication year of the ad hoc checklist as the date when the presence of the species was last verified, except for `Mephitis mephitis`, which was last observed in 2014. For this species, we use `2014` as start date:

```{r}
distribution %<>% mutate(start_date = case_when(
  input_scientific_name == "Mephitis mephitis (Schreber, 1776)" ~ "2014",
  is.na(input_date_first_observation) ~ "2018",
  TRUE ~ input_date_first_observation
)) 
```

`input_date_last_observation` should not be before 2018 for those specific records:

```{r}
distribution %>% 
  filter(is.na(input_date_first_observation)) %>%
  group_by(input_date_first_observation, start_date, input_date_last_observation) %>% 
  count()
```

Inspect `input_date_last_observation`:

```{r}
distribution %>%
  group_by(input_date_last_observation) %>%
  count()
```

In a similar way as for `input_date_first_observation`, we use the publication year of the ad hoc checklist when no end year is provided:

```{r}
distribution %<>% mutate(end_date = case_when(
  is.na(input_date_last_observation) ~ "2018",
  TRUE  ~ input_date_last_observation
)) 
```

Create `eventDate`:

```{r}
distribution %<>% mutate(eventDate = paste(start_date, end_date, sep = "/")) 
```

### source

Use the `input_source` field as is. Its content is expected to be concatenated with ` | ` for more than one reference.

```{r}
distribution %<>% mutate(source = input_source) 
```

## Post-processing

Remove the original columns:

```{r}
distribution %<>% select(-starts_with("input_"), -start_date, -end_date)
```

Sort on `taxonID`:

```{r}
distribution %<>% arrange(taxonID)
```

Preview data:

```{r}
distribution %>% head()
```

Save to CSV:

```{r}
write.csv(distribution, file = here("data", "processed", "distribution.csv"), na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

# Species profile extension

In this extension we will express broad habitat characteristics of the species (e.g. `isTerrestrial`) from `input_realm`.

## Pre-processing

Create a dataframe with unique taxa only (ignoring multiple distribution rows):

```{r start_species_profile}
species_profile <- input_data %>% distinct(input_taxon_id, .keep_all = TRUE)
```

Only keep records for which `input_realm` is not empty:

```{r}
species_profile %<>% filter(!is.na(input_realm))
```

Inspect values:

```{r}
species_profile %>%
  group_by(input_realm) %>%
  count()
```

## Term mapping

Map the data to [Species Profile](http://rs.gbif.org/extension/gbif/1.0/speciesprofile.xml).

### taxonID

```{r}
species_profile %<>% mutate(taxonID = input_taxon_id)
```

### isMarine

```{r}
species_profile %<>% mutate(isMarine = case_when(
  input_realm == "freshwater | marine" ~ "TRUE",
  input_realm == "estuarine" ~ "TRUE",
  TRUE ~ "FALSE"
)) 
```

### isFreshwater

```{r}
species_profile %<>% mutate(isFreshwater = case_when(
  input_realm == "freshwater" ~ "TRUE",
  input_realm == "freshwater | marine" ~ "TRUE",
  input_realm == "terrestrial | freshwater" ~ "TRUE",
  input_realm == "estuarine" ~ "TRUE",
  TRUE ~ "FALSE"
)) 
```

### isTerrestrial

```{r}
species_profile %<>% mutate(isTerrestrial = case_when(
  input_realm == "terrestrial" ~ "TRUE",
  input_realm == "terrestrial | freshwater" ~ "TRUE",
  TRUE ~ "FALSE"
))
```

Show mapped values:

```{r}
species_profile %>%
  select(input_realm, isMarine, isFreshwater, isTerrestrial) %>%
  group_by_all() %>%
  summarize(records = n())
```

## Post-processing

Remove the original columns:

```{r}
species_profile %<>% select(-starts_with("input_"))
```

Sort on `taxonID`:

```{r}
species_profile %<>% arrange(taxonID)
```

Preview data:

```{r}
species_profile %>% head()
```

Save to CSV:

```{r}
write.csv(species_profile, file = here("data", "processed", "speciesprofile.csv"), na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

# Description extension

In the description extension we want to include several important characteristics (hereafter referred to as descriptors) about the species:

- Native range
- Pathway of introduction
- Invasion stage

The structure of the description extension is slightly different from the other core/extension files: information for a specific taxon (linked to `taxonID`) is provided in **multiple** lines within the csv file: one line per taxon per descriptor. In this way, we are able to include multipele descriptors for each species.

For each descriptor, we create a separate dataframe to process the specific information. We always specify _which descriptor_ we map (`type` column) and its _specific content_ (`description` column). After the mapping of these Darwin Core terms `type` and `value`, we merge the dataframes to generate one single description extension. We then continue the mapping process by adding the other Darwin Core terms (which content is independent of the type of descriptor, such as `language`).

## Native range

We will express native range information from `input_native_range`, separated and gathered.

Create a dataframe with unique taxa only (ignoring multiple distribution rows):

```{r start_native_range}
native_range <- input_data %>% distinct(input_taxon_id, .keep_all = TRUE)
```

Separate values on `|` in a maximum of 3 columns:

```{r}
native_range %<>% separate(
  input_native_range,
  into = paste0("range_", c(1:3)),
  sep = " \\| ",
  extra = "drop"
)
```

Gather and trim values:

```{r}
native_range %<>% gather(key, value, starts_with("range_"), na.rm = TRUE) %>%
  mutate(value = str_trim(value))
```

Inspect values:

```{r}
native_range %>%
  group_by(value) %>%
  count()
```

Clean native range information in `value` somewhat:

```{r}
native_range %<>% 
  mutate(value = str_replace_all(value, "\\?", "")) %>%  # Remove question
  mutate(value = str_to_title(value))
```

Map values:

```{r}
native_range %<>% mutate(mapped_value = recode(value,
  "Africa"                 = "Africa (WGSRPD:2)",
  "Australa"               = "Australia (WGSRPD:50)",
  "Canary Islands"         = "Canary Islands (WGSRPD:21_CNY)",
  "Central America"        = "Central America (WGSRPD:80)",
  "China"                  = "China (WGSRPD:36)",
  "Costa Rica"             = "Costa Rica (WGSRPD:80_COS)",
  "Cyprus"                 = "Cyprus (WGSRPD:34_CYP)",
  "East Africa"            = "Eastern Africa",
  "East Asia"              = "Eastern Asia (WGSRPD:38)",
  "Europe"                 = "Europe (WGSRPD:1)",
  "Hawaï"                  = "Hawaii (WGSRPD:63_HAW)",
  "Japan"                  = "Japan (WGSRPD:38_JAP)",
  "Mexico"                 = "Mexico (WGSRPD:79)",
  "New Zealand"            = "New Zealand (WGSRPD:51)",
  "North Amercia"          = "Northern America (WGSRPD:7)",
  "South America"          = "Southern America (WGSRPD:8)",
  "Southeastern Europe"    = "Southeastern Europe (WGSRPD:13)",
  "Southern Africa "       = "Southern Africa (WGSRPD:27)",
  "Tasmania"               = "Tasmania (WGSRPD:50_TAS)",
  "Vietnam"                = "Vietnam (WGSRPD:41_VIE)",
# .default                 = "",
  .missing                 = ""
))
```

Inspect mapped values:

```{r}
native_range %>%
  group_by(value, mapped_value) %>%
  count()
```

Drop `key` and `value` column and rename `mapped value`:

```{r}
native_range %<>% 
  select(-key, -value) %>% 
  rename(description = mapped_value)
```

Keep only non-empty descriptions:

```{r}
native_range %<>% filter(!is.na(description) & description != "")
```

Create a `type` field to indicate the type of description:

```{r}
native_range %<>% mutate(type = "native range")
```

## Pathway of introduction

We will express pathway information (e.g. `aquaculture`) from `input_introduction_pathway`, separated and gathered.

Create a dataframe with unique taxa only (ignoring multiple distribution rows):

```{r start_pathway_description}
pathway_desc <- input_data %>% distinct(input_taxon_id, .keep_all = TRUE)
```

Separate values on `|` in a maximum of 2 columns:

```{r}
pathway_desc %<>% separate(
  input_introduction_pathway,
  into = paste0("range_", c(1:2)),
  sep = " \\| ",
  extra = "drop"
)
```

Gather and trim values:

```{r}
pathway_desc %<>% gather(key, value, starts_with("range_"), na.rm = TRUE) %>%
  mutate(value = str_trim(value))
```

Inspect values:

```{r}
pathway_desc %>%
  distinct(value) %>%
  arrange(value) 
```

We use the [CBD 2014 pathway vocabulary](https://www.cbd.int/doc/meetings/sbstta/sbstta-18/official/sbstta-18-09-add1-en.pdf) to standardize this information. The vocubulary has [these values](https://github.com/trias-project/vocab/tree/master/vocabulary/pathway).

The values in this checklist should already match to the CBD standard, but we'll do a regex match for lowercase and underscore strings as a check and prefix `cbd_2014_pathway` for those only:

```{r}
pathway_desc %<>% mutate(mapped_value = case_when(
  str_detect(value, "^[a-z_]+$") ~ paste("cbd_2014_pathway", value, sep = ":"),
  is.na(value) ~ "",
  TRUE ~ ""
))
```

Inspect mapped values:

```{r}
pathway_desc %>%
  group_by(value, mapped_value) %>%
  count()
```

Drop `key` and `value` column:

```{r}
pathway_desc %<>% select(-key, -value)
```

Change column name `mapped_value` to `description`:

```{r}
pathway_desc %<>%  rename(description = mapped_value)
```

Create a `type` field to indicate the type of description:

```{r}
pathway_desc %<>% mutate (type = "pathway")
```

Keep only non-empty descriptions:

```{r}
pathway_desc %<>% filter(!is.na(description) & description != "")
```

## Invasion stage

We will express invasion stage from `input_degree_of_establishment`.

Create a dataframe with unique taxa only (ignoring multiple distribution rows):

```{r start_invasion_stage}
invasion_stage <- input_data %>% distinct(input_taxon_id, .keep_all = TRUE)
```

Inspect values:

```{r}
invasion_stage %>%
  group_by(input_degree_of_establishment) %>%
  count()
```

Our vocabulary for invasion stage is based on the [invasion stage vocabulary from Blackburn et al. (2011)](http://doc.rero.ch/record/24725/files/bach_puf.pdf). We decided **not** to use the terms `naturalized` (because often, there's no sensible criterium to distinguish between casual/naturalized of naturalized/established) and `invasive` (which is a term that can only be applied after a risk assessment).

Map data to Blackburn at al. (2011) vocabulary:

```{r}
invasion_stage %<>% mutate(description = case_when(
  input_degree_of_establishment == "captive" | 
  input_degree_of_establishment == "casual" |
  input_degree_of_establishment == "cultivated" |
  input_degree_of_establishment == "reproducing" |
  input_degree_of_establishment == "transported" ~ "introduced",
  input_degree_of_establishment == "colonizing" |
  input_degree_of_establishment == "established" |
  input_degree_of_establishment == "invasive" ~ "established"
))
```

Remove empty values:

```{r}
invasion_stage %<>% filter(!is.na(description))
```

Show mapped values:

```{r}
invasion_stage %>%
  group_by(input_degree_of_establishment, description) %>%
  count()
```

Create a `type` field to indicate the type of description:

```{r}
invasion_stage %<>% mutate(type = "invasion stage")
```

## Union descriptions

Union native range, pathway of introduction and invasion stage:

```{r start_description_ext}
description_ext <- bind_rows(native_range, pathway_desc, invasion_stage)
```

## Term mapping

Map the data to [Taxon Description](http://rs.gbif.org/extension/gbif/1.0/description.xml).

### taxonID

```{r}
description_ext %<>% mutate(taxonID = input_taxon_id)
```

### description

```{r}
description_ext %<>% mutate(description = description)
```

### type

```{r}
description_ext %<>% mutate(type = type)
```

### language

```{r}
description_ext %<>% mutate(language = "en")
```

## Post-processing

Remove the original columns:

```{r}
description_ext %<>% select(-starts_with("input_"))
```

Move `taxonID` to the first position:

```{r}
description_ext %<>% select(taxonID, everything())
```

Sort on `taxonID` to group description information per taxon:

```{r}
description_ext %<>% arrange(taxonID)
```

Preview data:

```{r}
description_ext %>% head(10)
```

Save to CSV:

```{r}
write.csv(description_ext, file = here("data", "processed", "description.csv"), na = "", row.names = FALSE, fileEncoding = "UTF-8")
```
